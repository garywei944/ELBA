user input number of GPUS: 4
user input number of GPUS: 4
user input number of GPUS: 4
user input number of GPUS: 4
number of processes: 4

Process Grid (p x p x t): 2 x 2 x 1

INFO: ELBA started on Sat May  6 12:09:32 2023
  Input file (-i):                             ../ecoli_hifi_29x.fasta
  Original sequence count (-c):                8605
  K-mer length (k):                            31
  K-mer stride (s):                            1
  Overlap in bytes (-O):                       100000
  Top seed count (--sc):                       2
  Base match score (--ma):                     1
  Base mismatch score (--mi):                  -1
  Gap open penalty (-g):                       0
  Gap extension penalty (-e):                  -1
  Overlap file (--of):                         None
  Pairwise alignment file (--af):              ecoli-cpu
  alignmentlignment write frequency (--afreq): 100000
  Do not perform alignment (--na):             FALSE
  GPU alignment (--ga):                        TRUE | X: 15
  CPU-based alignment (--ca):                  FALSE
  Read index map (--idxmap):                   ecoli-idxmap
  Pairwise alignment alphabet (--alph):        1
  GPU number (--gpu):                          4

K-mer Counting and 'A' Creation started:
ProcessFiles: First pass: Table size is: 175411678 bits, 20.9107 MB
ProcessFiles: First pass: Optimal number of hash functions is : 5
A (sequences-by-kmer matrix): As a whole: 8605 rows and 3134024 columns and 78110966 nonzeros

Overlap Detection started:
C (sequences-by-sequences candidate matrix) = AA^T: As a whole: 8605 rows and 8605 columns and 473535 nonzeros

process 3 is responsible for 2 2 1 1
process 0 is responsible for 2 2 0 0
process 1 is responsible for 2 2 1 0
process 2 is responsible for 2 2 0 1
GPU-based LOGAN alignment started:
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
rank 1 starts epoch 0 / 2
actual gpu num: 4
actual gpu num: 4
rank 3 starts epoch 0 / 2
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 0 starts epoch 1 / 2
actual gpu num: 4
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 2 ends
rank 2 ack completion of gpu 0
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 1 ack completion of gpu 0
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 2 finish and release gpu 2
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 ack completion of gpu 0
rank 3 ack completion of gpu 2
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 1 finish and release gpu 1
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 2 ends
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 1 ack completion of gpu 0
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 ack completion of gpu 0
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 2 ends
rank 2 finish and release gpu 2
rank 3 ends
rank 3 ack completion of gpu 2
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 1 finish and release gpu 1
rank 0 ends
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 2 ends
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 ack completion of gpu 0
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 1 finish and release gpu 1
rank 2 ends
rank 2 finish and release gpu 2
rank 0 ends
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 2 ends
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 3 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 1 finish and release gpu 1
rank 2 ends
rank 2 finish and release gpu 2
rank 0 ends
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 2 ends
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 3 ends
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 1 finish and release gpu 1
rank 3 ends
rank 3 finish and release gpu 3
rank 2 ends
rank 2 finish and release gpu 2
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 3 ends
rank 1 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 1 ends
rank 1 finish and release gpu 1
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 2 ends
rank 2 finish and release gpu 2
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 1 ends
rank 1 finish and release gpu 1
rank 0 ends
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 2 ends
rank 2 finish and release gpu 2
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 1 ends
rank 1 finish and release gpu 1
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 2 finish and release gpu 2
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 2 ends
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 1 finish and release gpu 1
rank 2 ends
rank 2 finish and release gpu 2
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 1 ends
rank 2 ends
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 2 finish and release gpu 2
rank 1 ends
rank 1 finish and release gpu 1
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 1 ends
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 finish and release gpu 3
rank 3 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 2 finish and release gpu 2
rank 1 ends
rank 1 finish and release gpu 1
rank 2 starts epoch 0 / 2
actual gpu num: 4
rank 1 starts epoch 0 / 2
actual gpu num: 4
rank 3 ends
rank 3 starts epoch 1 / 2
actual gpu num: 4
rank 2 ends
rank 1 ends
rank 2 starts epoch 1 / 2
actual gpu num: 4
rank 1 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
Apply run batch with GPU passed from constructor:  4
rank 0 starts epoch 0 / 2
actual gpu num: 4
rank 0 ends
rank 0 starts epoch 1 / 2
actual gpu num: 4
rank 0 ends
rank 0 finish and release gpu 0
rank 2 ends
rank 2 finish and release gpu 2
rank 1 ends
rank 1 finish and release gpu 1
rank 3 ends
rank 3 finish and release gpu 3
#nonzeros in C before pruning: 473535
#nonzeros in C after score pruning: 134726
#nonzeros in C after contained sequences pruning: 21453
#alignment run (L-D-U): 232474
R (post-alignment result matrix): As a whole: 8605 rows and 8605 columns and 42906 nonzeros

Transitive Reduction started:
S (string matrix): As a whole: 8605 rows and 8605 columns and 6468 nonzeros

Contig Generation and Local Assembly started: 
Creating a new MPI Op for St4plusIdE
#connected components with size > 1: 14
Local Assembly time: 0.014403

INFO: ELBA completed on Sat May  6 12:11:06 2023

INFO: ELBA runtimes:
  Main:94316.369752 ms
  Main:newDFD():177.299329 ms
  Dfd:PfrReadFasta():93.890296 ms
  Dfd:newFD():62.493387 ms
  KmerOp:GenerateA:CardinalityHLL():68.201781 ms
  KmerOp:GenerateA:FirstPass():21389.973270 ms
  KmerOp:GenerateA:SecondPass():17468.750191 ms
  KmerOp:GenerateA:SpMatA():1551.369265 ms
  Main:GenerateA():41947.748133 ms
  Main:At():1982.144090 ms
  Main:AAt():19931.919770 ms
  Main:DfdWait():94.567035 ms
  Dfd:MPI_Waitall(seqs):0.000791 ms
  Main:DprAlign():29785.776524 ms
  Main:TransitiveReduction():57.940979 ms
  Main:ExtractContig():113.560329 ms
  CreateContig:GetRead2Contigs():75.630518 ms
  CreateContig:GetRead2ProcAssignments():1.850130 ms
  CreateContig:InducedSubgraphs2Procs():0.657268 ms
  CreateContig:BuildContigChains():0.220626 ms
  CreateContig:ReadExchange():9.779678 ms
  CreateContig:LocalAssembly():14.403851 ms
  Main:WriteContigs():12.182665 ms
GTL_DEBUG: [0] cudaHostUnregister: driver shutting down
GTL_DEBUG: [0] cudaHostUnregister: driver shutting down
GTL_DEBUG: [0] cudaHostUnregister: driver shutting down
GTL_DEBUG: [1] cudaHostUnregister: driver shutting down
GTL_DEBUG: [2] cudaHostUnregister: driver shutting down
